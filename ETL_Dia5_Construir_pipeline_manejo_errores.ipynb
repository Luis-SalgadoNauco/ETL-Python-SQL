{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5bcb985-4359-4ef1-8280-cf4ea3b65a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "from functools import wraps\n",
    "\n",
    "# Configurar logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('etl_ecommerce.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "logger = logging.getLogger('etl_ecommerce')\n",
    "\n",
    "def log_etapa(etapa):\n",
    "    \"\"\"Decorator para logging de etapas\"\"\"\n",
    "    def decorator(func):\n",
    "        @wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            logger.info(f\"Iniciando {etapa}\")\n",
    "            start_time = time.time()\n",
    "            \n",
    "            try:\n",
    "                result = func(*args, **kwargs)\n",
    "                duration = time.time() - start_time\n",
    "                logger.info(f\"{etapa} completada en {duration:.2f}s\")\n",
    "                return result\n",
    "            except Exception as e:\n",
    "                duration = time.time() - start_time\n",
    "                logger.error(f\"{etapa} falló en {duration:.2f}s: {e}\")\n",
    "                raise e\n",
    "        \n",
    "        return wrapper\n",
    "    return decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "826a47c8-6724-4ce0-98a9-b53bb6a9bb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, Any\n",
    "\n",
    "class ETLPipeline:\n",
    "    def __init__(self):\n",
    "        self.logger = logger\n",
    "        self.errores = []\n",
    "    \n",
    "    @log_etapa(\"extracción de datos\")\n",
    "    def extract(self) -> pd.DataFrame:\n",
    "        \"\"\"Extraer datos con manejo de errores\"\"\"\n",
    "        try:\n",
    "            # Simular extracción (podría fallar)\n",
    "            if np.random.random() < 0.1:  # 10% chance de error\n",
    "                raise ConnectionError(\"Error de conexión a fuente de datos\")\n",
    "            \n",
    "            # Datos de ejemplo\n",
    "            datos = pd.DataFrame({\n",
    "                'orden_id': range(1, 101),\n",
    "                'cliente_id': np.random.randint(1, 21, 100),\n",
    "                'producto': np.random.choice(['A', 'B', 'C', 'D'], 100),\n",
    "                'cantidad': np.random.randint(1, 6, 100),\n",
    "                'precio': np.round(np.random.uniform(10, 200, 100), 2)\n",
    "            })\n",
    "            \n",
    "            self.logger.info(f\"Extraídos {len(datos)} registros\")\n",
    "            return datos\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.errores.append(f\"Extract: {e}\")\n",
    "            raise e\n",
    "    \n",
    "    @log_etapa(\"transformación de datos\")\n",
    "    def transform(self, datos: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Transformar datos con validaciones\"\"\"\n",
    "        try:\n",
    "            df = datos.copy()\n",
    "            \n",
    "            # Validar datos de entrada\n",
    "            if df.empty:\n",
    "                raise ValueError(\"No hay datos para transformar\")\n",
    "            \n",
    "            # Transformaciones\n",
    "            df['total'] = df['cantidad'] * df['precio']\n",
    "            df['categoria_precio'] = pd.cut(\n",
    "                df['precio'], \n",
    "                bins=[0, 50, 100, 200], \n",
    "                labels=['Bajo', 'Medio', 'Alto']\n",
    "            )\n",
    "            \n",
    "            # Validar transformaciones\n",
    "            if df['total'].isnull().any():\n",
    "                raise ValueError(\"Transformación produjo valores nulos\")\n",
    "            \n",
    "            self.logger.info(f\"Transformados {len(df)} registros\")\n",
    "            return df\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.errores.append(f\"Transform: {e}\")\n",
    "            raise e\n",
    "    \n",
    "    @log_etapa(\"carga de datos\")\n",
    "    def load(self, datos: pd.DataFrame) -> bool:\n",
    "        \"\"\"Cargar datos con verificación\"\"\"\n",
    "        try:\n",
    "            # Simular carga (podría fallar)\n",
    "            if np.random.random() < 0.05:  # 5% chance de error\n",
    "                raise Exception(\"Error de conexión a base de datos\")\n",
    "            \n",
    "            # En producción: datos.to_sql('ventas', engine, if_exists='append')\n",
    "            self.logger.info(f\"Cargados {len(datos)} registros exitosamente\")\n",
    "            \n",
    "            # Validar carga\n",
    "            registros_esperados = len(datos)\n",
    "            registros_cargados = len(datos)  # Simulado\n",
    "            \n",
    "            if registros_cargados != registros_esperados:\n",
    "                raise ValueError(f\"Carga incompleta: {registros_cargados}/{registros_esperados}\")\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.errores.append(f\"Load: {e}\")\n",
    "            raise e\n",
    "    \n",
    "    def ejecutar_pipeline(self) -> Dict[str, Any]:\n",
    "        \"\"\"Ejecutar pipeline completo con manejo de errores\"\"\"\n",
    "        self.logger.info(\"Iniciando pipeline ETL completo\")\n",
    "        \n",
    "        try:\n",
    "            # Extract\n",
    "            datos_crudo = self.extract()\n",
    "            \n",
    "            # Transform\n",
    "            datos_transformados = self.transform(datos_crudo)\n",
    "            \n",
    "            # Load\n",
    "            exito = self.load(datos_transformados)\n",
    "            \n",
    "            resultado = {\n",
    "                'exito': True,\n",
    "                'registros_procesados': len(datos_transformados),\n",
    "                'errores': self.errores\n",
    "            }\n",
    "            \n",
    "            self.logger.info(\"Pipeline ETL completado exitosamente\")\n",
    "            return resultado\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Pipeline ETL falló: {e}\")\n",
    "            \n",
    "            return {\n",
    "                'exito': False,\n",
    "                'error_principal': str(e),\n",
    "                'errores': self.errores\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbc7a27a-88d2-46d9-8867-0aa2926a5efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-08 20:37:54,797 - INFO - Iniciando pipeline ETL completo\n",
      "2026-01-08 20:37:54,799 - INFO - Iniciando extracción de datos\n",
      "2026-01-08 20:37:54,803 - INFO - Extraídos 100 registros\n",
      "2026-01-08 20:37:54,805 - INFO - extracción de datos completada en 0.00s\n",
      "2026-01-08 20:37:54,807 - INFO - Iniciando transformación de datos\n",
      "2026-01-08 20:37:54,814 - INFO - Transformados 100 registros\n",
      "2026-01-08 20:37:54,817 - INFO - transformación de datos completada en 0.01s\n",
      "2026-01-08 20:37:54,820 - INFO - Iniciando carga de datos\n",
      "2026-01-08 20:37:54,823 - INFO - Cargados 100 registros exitosamente\n",
      "2026-01-08 20:37:54,825 - INFO - carga de datos completada en 0.00s\n",
      "2026-01-08 20:37:54,826 - INFO - Pipeline ETL completado exitosamente\n",
      "2026-01-08 20:37:54,831 - INFO - Iniciando pipeline ETL completo\n",
      "2026-01-08 20:37:54,833 - INFO - Iniciando extracción de datos\n",
      "2026-01-08 20:37:54,835 - ERROR - extracción de datos falló en 0.00s: Error de conexión a fuente de datos\n",
      "2026-01-08 20:37:54,836 - ERROR - Pipeline ETL falló: Error de conexión a fuente de datos\n",
      "2026-01-08 20:37:54,837 - INFO - Iniciando pipeline ETL completo\n",
      "2026-01-08 20:37:54,839 - INFO - Iniciando extracción de datos\n",
      "2026-01-08 20:37:54,841 - INFO - Extraídos 100 registros\n",
      "2026-01-08 20:37:54,843 - INFO - extracción de datos completada en 0.00s\n",
      "2026-01-08 20:37:54,846 - INFO - Iniciando transformación de datos\n",
      "2026-01-08 20:37:54,853 - INFO - Transformados 100 registros\n",
      "2026-01-08 20:37:54,854 - INFO - transformación de datos completada en 0.00s\n",
      "2026-01-08 20:37:54,856 - INFO - Iniciando carga de datos\n",
      "2026-01-08 20:37:54,859 - ERROR - carga de datos falló en 0.00s: Error de conexión a base de datos\n",
      "2026-01-08 20:37:54,862 - ERROR - Pipeline ETL falló: Error de conexión a base de datos\n",
      "2026-01-08 20:37:54,864 - INFO - Iniciando pipeline ETL completo\n",
      "2026-01-08 20:37:54,867 - INFO - Iniciando extracción de datos\n",
      "2026-01-08 20:37:54,871 - INFO - Extraídos 100 registros\n",
      "2026-01-08 20:37:54,873 - INFO - extracción de datos completada en 0.00s\n",
      "2026-01-08 20:37:54,875 - INFO - Iniciando transformación de datos\n",
      "2026-01-08 20:37:54,880 - INFO - Transformados 100 registros\n",
      "2026-01-08 20:37:54,882 - INFO - transformación de datos completada en 0.01s\n",
      "2026-01-08 20:37:54,884 - INFO - Iniciando carga de datos\n",
      "2026-01-08 20:37:54,885 - INFO - Cargados 100 registros exitosamente\n",
      "2026-01-08 20:37:54,886 - INFO - carga de datos completada en 0.00s\n",
      "2026-01-08 20:37:54,888 - INFO - Pipeline ETL completado exitosamente\n",
      "2026-01-08 20:37:54,890 - INFO - Iniciando pipeline ETL completo\n",
      "2026-01-08 20:37:54,891 - INFO - Iniciando extracción de datos\n",
      "2026-01-08 20:37:54,895 - INFO - Extraídos 100 registros\n",
      "2026-01-08 20:37:54,896 - INFO - extracción de datos completada en 0.00s\n",
      "2026-01-08 20:37:54,897 - INFO - Iniciando transformación de datos\n",
      "2026-01-08 20:37:54,901 - INFO - Transformados 100 registros\n",
      "2026-01-08 20:37:54,902 - INFO - transformación de datos completada en 0.00s\n",
      "2026-01-08 20:37:54,904 - INFO - Iniciando carga de datos\n",
      "2026-01-08 20:37:54,905 - INFO - Cargados 100 registros exitosamente\n",
      "2026-01-08 20:37:54,907 - INFO - carga de datos completada en 0.00s\n",
      "2026-01-08 20:37:54,909 - INFO - Pipeline ETL completado exitosamente\n",
      "2026-01-08 20:37:54,911 - INFO - Iniciando pipeline ETL completo\n",
      "2026-01-08 20:37:54,913 - INFO - Iniciando extracción de datos\n",
      "2026-01-08 20:37:54,916 - INFO - Extraídos 100 registros\n",
      "2026-01-08 20:37:54,917 - INFO - extracción de datos completada en 0.00s\n",
      "2026-01-08 20:37:54,917 - INFO - Iniciando transformación de datos\n",
      "2026-01-08 20:37:54,921 - INFO - Transformados 100 registros\n",
      "2026-01-08 20:37:54,924 - INFO - transformación de datos completada en 0.01s\n",
      "2026-01-08 20:37:54,926 - INFO - Iniciando carga de datos\n",
      "2026-01-08 20:37:54,928 - ERROR - carga de datos falló en 0.00s: Error de conexión a base de datos\n",
      "2026-01-08 20:37:54,931 - ERROR - Pipeline ETL falló: Error de conexión a base de datos\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultado del pipeline:\n",
      "Éxito: True\n",
      "Registros procesados: 100\n",
      "Errores registrados: 0\n",
      "\n",
      "--- Ejecución 1 ---\n",
      "\n",
      "--- Ejecución 2 ---\n",
      "\n",
      "--- Ejecución 3 ---\n",
      "\n",
      "--- Ejecución 4 ---\n",
      "\n",
      "--- Ejecución 5 ---\n",
      "Tasa de éxito: 40.0%\n"
     ]
    }
   ],
   "source": [
    "# Ejecutar pipeline con diferentes escenarios\n",
    "pipeline = ETLPipeline()\n",
    "\n",
    "# Ejecución exitosa\n",
    "resultado = pipeline.ejecutar_pipeline()\n",
    "\n",
    "print(f\"\\nResultado del pipeline:\")\n",
    "print(f\"Éxito: {resultado['exito']}\")\n",
    "if resultado['exito']:\n",
    "    print(f\"Registros procesados: {resultado['registros_procesados']}\")\n",
    "else:\n",
    "    print(f\"Error principal: {resultado['error_principal']}\")\n",
    "\n",
    "print(f\"Errores registrados: {len(resultado['errores'])}\")\n",
    "for error in resultado['errores']:\n",
    "    print(f\"  - {error}\")\n",
    "\n",
    "# Ejecutar múltiples veces para probar robustez\n",
    "resultados_multiples = []\n",
    "for i in range(5):\n",
    "    print(f\"\\n--- Ejecución {i+1} ---\")\n",
    "    pipeline_i = ETLPipeline()\n",
    "    resultado_i = pipeline_i.ejecutar_pipeline()\n",
    "    resultados_multiples.append(resultado_i['exito'])\n",
    "\n",
    "exito_rate = sum(resultados_multiples) / len(resultados_multiples)\n",
    "print(f\"Tasa de éxito: {exito_rate:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e11d3121-9374-4555-870f-95f97ab09b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-08 20:41:50,640 - INFO - Iniciando extracción de datos\n",
      "2026-01-08 20:41:50,642 - INFO - Iniciando extracción de datos\n",
      "2026-01-08 20:41:50,646 - INFO - Extraídos 100 registros\n",
      "2026-01-08 20:41:50,648 - INFO - Iniciando transformación de datos\n",
      "2026-01-08 20:41:50,657 - INFO - Transformados 100 registros\n",
      "2026-01-08 20:41:50,660 - INFO - Iniciando carga de datos\n",
      "2026-01-08 20:41:50,661 - INFO - Cargados 100 registros exitosamente\n",
      "2026-01-08 20:41:50,662 - INFO - Iniciando extracción de datos\n",
      "2026-01-08 20:41:50,667 - INFO - Extraídos 100 registros\n",
      "2026-01-08 20:41:50,671 - INFO - Iniciando transformación de datos\n",
      "2026-01-08 20:41:50,676 - INFO - Transformados 100 registros\n",
      "2026-01-08 20:41:50,678 - INFO - Iniciando carga de datos\n",
      "2026-01-08 20:41:50,679 - INFO - Cargados 100 registros exitosamente\n",
      "2026-01-08 20:41:50,681 - INFO - Iniciando extracción de datos\n",
      "2026-01-08 20:41:50,684 - INFO - Extraídos 100 registros\n",
      "2026-01-08 20:41:50,686 - INFO - Iniciando transformación de datos\n",
      "2026-01-08 20:41:50,690 - INFO - Transformados 100 registros\n",
      "2026-01-08 20:41:50,692 - INFO - Iniciando carga de datos\n",
      "2026-01-08 20:41:50,694 - INFO - Iniciando extracción de datos\n",
      "2026-01-08 20:41:50,699 - INFO - Extraídos 100 registros\n",
      "2026-01-08 20:41:50,701 - INFO - Iniciando transformación de datos\n",
      "2026-01-08 20:41:50,703 - INFO - Transformados 100 registros\n",
      "2026-01-08 20:41:50,704 - INFO - Iniciando carga de datos\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Evidencia generada: evidencia_etl_dia5.xlsx\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_ejecuciones</th>\n",
       "      <th>ejecuciones_exitosas</th>\n",
       "      <th>ejecuciones_fallidas</th>\n",
       "      <th>tasa_exito_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_ejecuciones  ejecuciones_exitosas  ejecuciones_fallidas  tasa_exito_%\n",
       "0                  5                     2                     3          40.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "# ----------------------------\n",
    "# Configuración de logging\n",
    "# ----------------------------\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(\"etl_pipeline\")\n",
    "\n",
    "# ----------------------------\n",
    "# Pipeline ETL\n",
    "# ----------------------------\n",
    "class ETLPipeline:\n",
    "\n",
    "    def extract(self):\n",
    "        logger.info(\"Iniciando extracción de datos\")\n",
    "        if random.random() < 0.2:\n",
    "            raise Exception(\"Error de conexión a fuente de datos\")\n",
    "\n",
    "        df = pd.DataFrame({\n",
    "            \"orden_id\": range(1, 101),\n",
    "            \"cliente_id\": np.random.randint(1, 20, 100),\n",
    "            \"producto\": np.random.choice(list(\"ABCD\"), 100),\n",
    "            \"cantidad\": np.random.randint(1, 6, 100),\n",
    "            \"precio\": np.round(np.random.uniform(10, 200, 100), 2)\n",
    "        })\n",
    "\n",
    "        logger.info(f\"Extraídos {len(df)} registros\")\n",
    "        return df\n",
    "\n",
    "    def transform(self, df):\n",
    "        logger.info(\"Iniciando transformación de datos\")\n",
    "        df = df.copy()\n",
    "        df[\"total\"] = df[\"cantidad\"] * df[\"precio\"]\n",
    "        df[\"categoria_precio\"] = df[\"total\"].apply(\n",
    "            lambda x: \"Alto\" if x >= 200 else \"Bajo\"\n",
    "        )\n",
    "        logger.info(f\"Transformados {len(df)} registros\")\n",
    "        return df\n",
    "\n",
    "    def load(self, df):\n",
    "        logger.info(\"Iniciando carga de datos\")\n",
    "        if random.random() < 0.2:\n",
    "            raise Exception(\"Error de conexión a base de datos\")\n",
    "        logger.info(f\"Cargados {len(df)} registros exitosamente\")\n",
    "\n",
    "    def run(self):\n",
    "        df = self.extract()\n",
    "        df = self.transform(df)\n",
    "        self.load(df)\n",
    "        return df\n",
    "\n",
    "# ----------------------------\n",
    "# Ejecuciones del pipeline\n",
    "# ----------------------------\n",
    "pipeline = ETLPipeline()\n",
    "ejecuciones = []\n",
    "df_final = None\n",
    "\n",
    "N_EJECUCIONES = 5\n",
    "\n",
    "for i in range(1, N_EJECUCIONES + 1):\n",
    "    try:\n",
    "        df_final = pipeline.run()\n",
    "        ejecuciones.append({\n",
    "            \"ejecucion\": i,\n",
    "            \"timestamp\": datetime.now(),\n",
    "            \"registros_procesados\": len(df_final),\n",
    "            \"estado\": \"Éxito\",\n",
    "            \"etapa_error\": None,\n",
    "            \"detalle_error\": None\n",
    "        })\n",
    "    except Exception as e:\n",
    "        ejecuciones.append({\n",
    "            \"ejecucion\": i,\n",
    "            \"timestamp\": datetime.now(),\n",
    "            \"registros_procesados\": 0,\n",
    "            \"estado\": \"Fallido\",\n",
    "            \"etapa_error\": \"ETL\",\n",
    "            \"detalle_error\": str(e)\n",
    "        })\n",
    "\n",
    "df_ejecuciones = pd.DataFrame(ejecuciones)\n",
    "\n",
    "# ----------------------------\n",
    "# Resumen del ETL\n",
    "# ----------------------------\n",
    "total = len(df_ejecuciones)\n",
    "exitos = (df_ejecuciones[\"estado\"] == \"Éxito\").sum()\n",
    "fallos = total - exitos\n",
    "tasa_exito = round(exitos / total * 100, 2)\n",
    "\n",
    "df_resumen = pd.DataFrame([{\n",
    "    \"total_ejecuciones\": total,\n",
    "    \"ejecuciones_exitosas\": exitos,\n",
    "    \"ejecuciones_fallidas\": fallos,\n",
    "    \"tasa_exito_%\": tasa_exito\n",
    "}])\n",
    "\n",
    "# ----------------------------\n",
    "# Exportar evidencia a Excel\n",
    "# ----------------------------\n",
    "with pd.ExcelWriter(\"evidencia_etl_dia5.xlsx\") as writer:\n",
    "    if df_final is not None:\n",
    "        df_final.to_excel(writer, sheet_name=\"datos_transformados\", index=False)\n",
    "    df_ejecuciones.to_excel(writer, sheet_name=\"ejecuciones_pipeline\", index=False)\n",
    "    df_resumen.to_excel(writer, sheet_name=\"resumen_etl\", index=False)\n",
    "\n",
    "print(\"✅ Evidencia generada: evidencia_etl_dia5.xlsx\")\n",
    "df_resumen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc0fba6-5786-43e8-8fcd-509cfb3d3cd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
